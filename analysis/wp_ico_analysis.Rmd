---
title: "wp_ico_analysis"
author: "Michael Rosenberg and Michael McCaffrey"
date: "11/10/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#packages
library(lubridate)
library(tree)
library(ggplot2)
#helpers
pch_lev = 19
percent_lev = 100
```

```{r load_data}
setwd(dir = "~/Dropbox/repos/page_count_crypto_analysis")
wp_ico_frame <- read.csv("~/Dropbox/repos/page_count_crypto_analysis/data/raw/wp_ico.csv",header = TRUE)
```

# Data Sanity Checks

```{r sanity_check}
dim(wp_ico_frame)
#more lines than expected; delete statistics rows
colnames(wp_ico_frame)
shit_row_start <- 440
shit_row_vec <- seq(from = shit_row_start,to = dim(wp_ico_frame)[1],
                    by = 1)
wp_ico_frame <- wp_ico_frame[-shit_row_vec,]
dim(wp_ico_frame)
```

# EDA

```{r target_var}
#cleanup from dollar to numeric
wp_ico_frame$amount_raised_m <- as.numeric(gsub('[$,]', '',
                                           wp_ico_frame$Amount.Raised.in.ICO...M.))
hist(wp_ico_frame$amount_raised_m,
     main = "Distribution of Amount Raised ($M)",
     ylab = "Count",
     xlab = "Amount Raised ($M)",
     col = "blue")
```
_Figure 1: Distribution of Amount Raised (In Millions)._

Looks very right skewed. Let us $\log$ it.

```{r, transform_target}
wp_ico_frame$log_amt_raised_m <- log(wp_ico_frame$amount_raised_m)
hist(wp_ico_frame$log_amt_raised_m,
     main = "Distribution of Log-Amount Raised",
     ylab = "Count",
     xlab = "Log-Amount Raised",
     col = "blue")
```
_Figure 2: Distribution of $\log$-Ammount Raised._

```{r, predict_var}
wp_ico_frame$Page.count <- as.numeric(wp_ico_frame$Page.count)
hist(wp_ico_frame$Page.count,
     main = "Distribution of Page Count",
     ylab = "Frequency",
     xlab = "Page Count",
     col = "blue")
```
_Figure 3: Distribution of Page Count._

```{r, init_scatterplot}
plot(x = wp_ico_frame$Page.count,
     y = wp_ico_frame$log_amt_raised_m,
     pch = pch_lev,
     main = "Log-Amount Raised on Page Count",
     ylab = "Log-Amount Raised (M)",
     xlab = "Page Count")
```
_Figure 4: $\log$-Amount Raised on Page Count._



# Initial Modeling

```{r, construct_init_mod}
init_mod_lm <- lm(log_amt_raised_m ~ Page.count,data = wp_ico_frame)
summary(init_mod_lm)
```

```{r, interpret_page_count_effect}
page_count_coef <- coefficients(init_mod_lm)["Page.count"]
#log(var) ~ page_count -> var ~ exp(page_count)
page_count_mul = exp(page_count_coef)
amount_raised_increase <- (page_count_mul - 1) * percent_lev
amount_raised_increase
```
This suggests to me that there isn't a strong global effect of page count on
amount.

```{r, generate_cutoff_var}
page_cutoff_of_interest <- 55
wp_ico_frame$above_cutoff <- wp_ico_frame$Page.count >= page_cutoff_of_interest
```

```{r, test_cutoff_var_in_mod}
cutoff_mod_lm <- lm(log_amt_raised_m ~ above_cutoff,data = wp_ico_frame)
summary(cutoff_mod_lm)
```

```{r,interpret_cutoff_coef}
cutoff_coef <- coefficients(cutoff_mod_lm)["above_cutoffTRUE"]
cutoff_impact_mul <- exp(cutoff_coef)
impact_percent_increase = (cutoff_impact_mul - 1) * percent_lev
impact_percent_increase
```
While the cutoff effect is not statistically significant, we can see by the
percent effect that it implies a lot of financial significance. This suggests
that the base effect is very strong, we just don't have enough data to claim
statistical significance in this context.

# Robust to Time

We're wondering if there are particular time effects that are confounding this
process. In particular, it might just be the case that all the heavy whitepapers
were released early in the year, which would suggest that the burndown on the
cryptocurrency craze is really inform the ICO-generating process. Let's plot
that.

```{r,extract_month}
wp_ico_frame$month_of_close <- month(
                                    as.POSIXct(wp_ico_frame$ICO.Close.Date,
                                               format = "%m/%d/%y"))
```

```{r,conditional_plot_on_month}
#get color vector
col_set <- colorRampPalette(c("blue","red"))
num_months <- length(unique(wp_ico_frame$month_of_close))
col_map_vec <- col_set(num_months)
col_application <- function(month,col_map_vec){
    return(col_map_vec[month])
}
col_application(1,col_map_vec)
col_row_vec <- sapply(wp_ico_frame$month_of_close,
                      col_application,
                      col_map_vec = col_map_vec)
#then plot
plot(x = wp_ico_frame$Page.count,
     y = wp_ico_frame$log_amt_raised_m,
     pch = pch_lev,
     col = col_row_vec,
     main = "Log-Amount Raised on Page Count\n(Conditioned on Month)",
     ylab = "Log-Amount Raised (M)",
     xlab = "Page Count")
legend("topright",legend = unique(wp_ico_frame$month_of_close),
       col = col_map_vec,title = "Month")
```
_Figure 5: $\log$-Amount Raised ($M) on page count, conditioned on month.
earlier months are colored in blue, while later months are colored in red._

```{r,month_conditioned_mod}
month_conditoned_lm <- lm(log_amt_raised_m ~ above_cutoff + as.factor(month_of_close),
                          data = wp_ico_frame)
summary(month_conditoned_lm)
```

# Tree-based Model

Let's try to calibrate for the optimal split point by looking at the outcomes of a decision tree for this analysis.

```{r,tree_based_model}
init_mod_tree <- tree(log_amt_raised_m ~ above_cutoff + as.factor(month_of_close),
                          data = wp_ico_frame)
plot(init_mod_tree)
text(init_mod_tree,pretty = TRUE)
```
_Figure 6: Decision tree for our current parameter set._

We can see by this fit that our cutoff is rather arbitrary and the decision tree
model sees no statistical significance around that cutoff. However, does a
decision tree find _any_ statistical significance within this page count
variable?

```{r,tree_based_model_raw_page_count}
page_count_tree <- tree(log_amt_raised_m ~ Page.count,data = wp_ico_frame)
plot(page_count_tree)
text(page_count_tree,pretty = TRUE)
```
_Figure 7: Tree of $\log(close_amt)$ on page count._

We can see that we weren't entirely off when we chose $54$ pages as a cutoff,
but nonetheless the tree-based approach seems to find $53.5$ to be the more
statistically significant cutoff. What is it about that $[53.5,55]% range that
we should be conscious of?

```{r,cutoff_investigation}
wp_ico_frame[
        wp_ico_frame$Page.count == (page_cutoff_of_interest - 1),
        c("Project","log_amt_raised_m","Page.count")]
```
_Table X: Projects at the $54$ page cutoff._

Looks like there are a lot of important samples right at this cutoff. This
suggests that we should really be keeping the cutoff at $54$ rather than $55$.

# Collinearity Checks

```{r,page_count_on_month}
#plot out values
tree_binary_line <- 53.5
(
    ggplot(wp_ico_frame,aes(x = month_of_close,y = Page.count)) 
        + geom_point()
        #plot mean
        + stat_summary(aes(y = Page.count,group = 1),fun.y = mean,colour = "blue",
                       geom = "line",group = 1)
        #plot line
        + geom_hline(yintercept = tree_binary_line,linetype = "dashed",
                     colour = "red")
        + xlab("Month of ICO Close")
        + ylab("Page Count")
        + ggtitle("Page Count on Month of Close")
)
```
_Figure 8: Page Count on Month of ICO close. Red dashed line is our decision
tree cutoff. Blue line is our month-to-month page count mean._

It's apparent here that the page count effect really isn't correlated with our
time effects. Month-to-month, the page count distribution does not substantially
change.

# Percentile-based Model

Let's try out a similar linear model but, rather than using a cutoff on exact
page count, let's do a cutoff on percentile.

```{r,engineer_percentile_var}
#normalize page count
min_page_count <- min(wp_ico_frame$Page.count)
max_page_count <- max(wp_ico_frame$Page.count)
norm_page_count <- ((wp_ico_frame$Page.count - min_page_count)
                    / (max_page_count - min_page_count))
page_percentile <- norm_page_count * percent_lev
wp_ico_frame$page_count_percentile <- page_percentile
```

```{r,fit_to_percentile_var}
page_count_tree <- tree(log_amt_raised_m ~ page_count_percentile,
                        data = wp_ico_frame)
plot(page_count_tree)
text(page_count_tree,pretty = TRUE)
```
